{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65136dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['# Week 2: AI Matching with TF-IDF\\n',\n",
       "    '\\n',\n",
       "    'In this notebook, we build our first AI-powered job-candidate matching system using TF-IDF vectors and cosine similarity. ']},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {},\n",
       "   'source': ['# Step 0: Install missing packages automatically\\n',\n",
       "    'import sys\\n',\n",
       "    'import subprocess\\n',\n",
       "    'import importlib\\n',\n",
       "    '\\n',\n",
       "    'def install_if_missing(package):\\n',\n",
       "    '    try:\\n',\n",
       "    '        importlib.import_module(package)\\n',\n",
       "    '    except ImportError:\\n',\n",
       "    '        print(f\"Installing {package}...\")\\n',\n",
       "    '        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\\n',\n",
       "    '\\n',\n",
       "    'packages = [\"pandas\", \"scikit-learn\", \"matplotlib\", \"seaborn\"]\\n',\n",
       "    'for pkg in packages:\\n',\n",
       "    '    install_if_missing(pkg)']},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {},\n",
       "   'source': ['# Step 1: Imports\\n',\n",
       "    'import pandas as pd\\n',\n",
       "    'import json\\n',\n",
       "    'from sklearn.feature_extraction.text import TfidfVectorizer\\n',\n",
       "    'from sklearn.metrics.pairwise import cosine_similarity\\n',\n",
       "    'import matplotlib.pyplot as plt\\n',\n",
       "    'import seaborn as sns']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## Step 2: Load JSON data\\n',\n",
       "    'We load job descriptions and candidate profiles from the `data/` folder.']},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {},\n",
       "   'source': ['# Load jobs safely\\n',\n",
       "    'jobs_path = \"../data/jobs/sample_jobs.json\"\\n',\n",
       "    'candidates_path = \"../data/candidates/sample_candidates.json\"\\n',\n",
       "    '\\n',\n",
       "    'def load_json(path):\\n',\n",
       "    \"    with open(path, 'r') as f:\\n\",\n",
       "    '        return json.load(f) if f.readable() else []\\n',\n",
       "    '\\n',\n",
       "    'jobs = load_json(jobs_path)\\n',\n",
       "    'candidates = load_json(candidates_path)\\n',\n",
       "    '\\n',\n",
       "    '# Convert to DataFrames\\n',\n",
       "    'jobs_df = pd.DataFrame(jobs)\\n',\n",
       "    'candidates_df = pd.DataFrame(candidates)\\n',\n",
       "    '\\n',\n",
       "    'jobs_df, candidates_df']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## Step 3: Combine text fields\\n',\n",
       "    'We combine titles, descriptions, and skills for jobs, and summary + skills for candidates into a single text field.']},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {},\n",
       "   'source': ['def combine_text(row):\\n',\n",
       "    '    return \" \".join([\\n',\n",
       "    '        row.get(\"title\", \"\"),\\n',\n",
       "    '        row.get(\"description\", \"\"),\\n',\n",
       "    '        \" \".join(row.get(\"skills\", []))\\n',\n",
       "    '    ])\\n',\n",
       "    '\\n',\n",
       "    'jobs_df[\"text\"] = jobs_df.apply(combine_text, axis=1)\\n',\n",
       "    'candidates_df[\"text\"] = candidates_df.apply(lambda r: r.get(\"summary\", \"\") + \" \" + \" \".join(r.get(\"skills\", [])), axis=1)\\n',\n",
       "    '\\n',\n",
       "    'jobs_df[[\"job_id\",\"text\"]], candidates_df[[\"candidate_id\",\"text\"]]']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## Step 4: Compute TF-IDF vectors\\n',\n",
       "    'We convert text into numerical vectors that can be compared.']},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {},\n",
       "   'source': ['all_text = list(jobs_df[\"text\"]) + list(candidates_df[\"text\"])\\n',\n",
       "    'vectorizer = TfidfVectorizer()\\n',\n",
       "    'vectorizer.fit(all_text)\\n',\n",
       "    '\\n',\n",
       "    'job_vectors = vectorizer.transform(jobs_df[\"text\"])\\n',\n",
       "    'candidate_vectors = vectorizer.transform(candidates_df[\"text\"])']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## Step 5: Compute Cosine Similarity\\n',\n",
       "    'This gives a score for each job-candidate pair.']},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {},\n",
       "   'source': ['similarity = cosine_similarity(job_vectors, candidate_vectors)\\n',\n",
       "    'similarity']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## Step 6: Print Ranked Matches']},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {},\n",
       "   'source': ['for i, job in jobs_df.iterrows():\\n',\n",
       "    '    print(f\"Job: {job[\\'title\\']}\")\\n',\n",
       "    '    scores = similarity[i]\\n',\n",
       "    '    for j, cand in candidates_df.iterrows():\\n',\n",
       "    '        print(f\"  Candidate: {cand[\\'candidate_id\\']}, score: {scores[j]:.2f}\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## Step 7: Visualize Matches']},\n",
       "  {'cell_type': 'code',\n",
       "   'metadata': {},\n",
       "   'source': ['sns.heatmap(similarity, annot=True, xticklabels=candidates_df[\"candidate_id\"], yticklabels=jobs_df[\"job_id\"])\\n',\n",
       "    'plt.title(\"Job-Candidate Similarity\")\\n',\n",
       "    'plt.show()']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### ✅ Week 2 Summary\\n',\n",
       "    '- Loaded jobs and candidates from JSON\\n',\n",
       "    '- Combined text fields into a single representation\\n',\n",
       "    '- Computed TF-IDF vectors\\n',\n",
       "    '- Calculated cosine similarity\\n',\n",
       "    '- Visualized matches\\n',\n",
       "    '- Notebook installs required packages automatically\\n',\n",
       "    '\\n',\n",
       "    'This notebook is **ready to commit to GitHub** for Week 2.']}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'name': 'python', 'version': '3.13'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 5}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Week 2: AI Matching with TF-IDF\\n\",\n",
    "    \"\\n\",\n",
    "    \"In this notebook, we build our first AI-powered job-candidate matching system using TF-IDF vectors and cosine similarity. \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Step 0: Install missing packages automatically\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import subprocess\\n\",\n",
    "    \"import importlib\\n\",\n",
    "    \"\\n\",\n",
    "    \"def install_if_missing(package):\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        importlib.import_module(package)\\n\",\n",
    "    \"    except ImportError:\\n\",\n",
    "    \"        print(f\\\"Installing {package}...\\\")\\n\",\n",
    "    \"        subprocess.check_call([sys.executable, \\\"-m\\\", \\\"pip\\\", \\\"install\\\", package])\\n\",\n",
    "    \"\\n\",\n",
    "    \"packages = [\\\"pandas\\\", \\\"scikit-learn\\\", \\\"matplotlib\\\", \\\"seaborn\\\"]\\n\",\n",
    "    \"for pkg in packages:\\n\",\n",
    "    \"    install_if_missing(pkg)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Step 1: Imports\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"from sklearn.feature_extraction.text import TfidfVectorizer\\n\",\n",
    "    \"from sklearn.metrics.pairwise import cosine_similarity\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 2: Load JSON data\\n\",\n",
    "    \"We load job descriptions and candidate profiles from the `data/` folder.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load jobs safely\\n\",\n",
    "    \"jobs_path = \\\"../data/jobs/sample_jobs.json\\\"\\n\",\n",
    "    \"candidates_path = \\\"../data/candidates/sample_candidates.json\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"def load_json(path):\\n\",\n",
    "    \"    with open(path, 'r') as f:\\n\",\n",
    "    \"        return json.load(f) if f.readable() else []\\n\",\n",
    "    \"\\n\",\n",
    "    \"jobs = load_json(jobs_path)\\n\",\n",
    "    \"candidates = load_json(candidates_path)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Convert to DataFrames\\n\",\n",
    "    \"jobs_df = pd.DataFrame(jobs)\\n\",\n",
    "    \"candidates_df = pd.DataFrame(candidates)\\n\",\n",
    "    \"\\n\",\n",
    "    \"jobs_df, candidates_df\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 3: Combine text fields\\n\",\n",
    "    \"We combine titles, descriptions, and skills for jobs, and summary + skills for candidates into a single text field.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def combine_text(row):\\n\",\n",
    "    \"    return \\\" \\\".join([\\n\",\n",
    "    \"        row.get(\\\"title\\\", \\\"\\\"),\\n\",\n",
    "    \"        row.get(\\\"description\\\", \\\"\\\"),\\n\",\n",
    "    \"        \\\" \\\".join(row.get(\\\"skills\\\", []))\\n\",\n",
    "    \"    ])\\n\",\n",
    "    \"\\n\",\n",
    "    \"jobs_df[\\\"text\\\"] = jobs_df.apply(combine_text, axis=1)\\n\",\n",
    "    \"candidates_df[\\\"text\\\"] = candidates_df.apply(lambda r: r.get(\\\"summary\\\", \\\"\\\") + \\\" \\\" + \\\" \\\".join(r.get(\\\"skills\\\", [])), axis=1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"jobs_df[[\\\"job_id\\\",\\\"text\\\"]], candidates_df[[\\\"candidate_id\\\",\\\"text\\\"]]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 4: Compute TF-IDF vectors\\n\",\n",
    "    \"We convert text into numerical vectors that can be compared.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"all_text = list(jobs_df[\\\"text\\\"]) + list(candidates_df[\\\"text\\\"])\\n\",\n",
    "    \"vectorizer = TfidfVectorizer()\\n\",\n",
    "    \"vectorizer.fit(all_text)\\n\",\n",
    "    \"\\n\",\n",
    "    \"job_vectors = vectorizer.transform(jobs_df[\\\"text\\\"])\\n\",\n",
    "    \"candidate_vectors = vectorizer.transform(candidates_df[\\\"text\\\"])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 5: Compute Cosine Similarity\\n\",\n",
    "    \"This gives a score for each job-candidate pair.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"similarity = cosine_similarity(job_vectors, candidate_vectors)\\n\",\n",
    "    \"similarity\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 6: Print Ranked Matches\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"for i, job in jobs_df.iterrows():\\n\",\n",
    "    \"    print(f\\\"Job: {job['title']}\\\")\\n\",\n",
    "    \"    scores = similarity[i]\\n\",\n",
    "    \"    for j, cand in candidates_df.iterrows():\\n\",\n",
    "    \"        print(f\\\"  Candidate: {cand['candidate_id']}, score: {scores[j]:.2f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 7: Visualize Matches\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"sns.heatmap(similarity, annot=True, xticklabels=candidates_df[\\\"candidate_id\\\"], yticklabels=jobs_df[\\\"job_id\\\"])\\n\",\n",
    "    \"plt.title(\\\"Job-Candidate Similarity\\\")\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### ✅ Week 2 Summary\\n\",\n",
    "    \"- Loaded jobs and candidates from JSON\\n\",\n",
    "    \"- Combined text fields into a single representation\\n\",\n",
    "    \"- Computed TF-IDF vectors\\n\",\n",
    "    \"- Calculated cosine similarity\\n\",\n",
    "    \"- Visualized matches\\n\",\n",
    "    \"- Notebook installs required packages automatically\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook is **ready to commit to GitHub** for Week 2.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.13\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
